{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICCION DE FASE USANDO NPL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Importe De Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Diego\n",
      "[nltk_data]     Ojeda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from pylab import *\n",
    "import seaborn as sns\n",
    "from IPython.core.interactiveshell import InteractiveShell  \n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from IPython.display import display, HTML\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from statistics import mean\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import preprocessing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import pickle\n",
    "import nltk\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "from dash import Dash, dash_table\n",
    "import dash_html_components as html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_pro_well(base,well):\n",
    "    '''\n",
    "    FUNCION QUE SELECCIONA UN POZO, TRANSFORMA LOS DATOS COMO INPUT DEL MODELO\n",
    "\n",
    "    - base: Dataframe con los datos de todos los pozos.\n",
    "    - well: cadena de caracteres con el nombre del pozo a evaluar    \n",
    "    '''\n",
    "\n",
    "    # Seleccion del pozo a preprocesar\n",
    "    base = base[base[\"Nombre\"]==well]\n",
    "\n",
    "    # Seleccion de la columna de tesxto\n",
    "    X = base[\"Operaci贸n\"]\n",
    "\n",
    "    # Libreria de stopwords en ingles\n",
    "    nltk.download('wordnet')\n",
    "\n",
    "    # Lista de textos vacia\n",
    "    documents = []\n",
    "    \n",
    "    # Instanciacion del lematizador en ingles\n",
    "    stemmer = WordNetLemmatizer()\n",
    "\n",
    "    # Ciclo for para que recorra todos las filas con las actividaes (textos)\n",
    "    for sen in range(0, len(X)):\n",
    "\n",
    "        # Removemos los caracteres especiales\n",
    "        document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "        \n",
    "        # Removemos todos las cadenas de caracteres de un solo caracter\n",
    "        document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "        \n",
    "        # Removemos caracteres sencillso al inicio\n",
    "        document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "        \n",
    "        # Substituimos dobles espacios por espacios sencillos\n",
    "        document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "        # Removemos caracteres numericos\n",
    "        document = re.sub(r'\\[[0-9]*\\]',' ',document)\n",
    "        \n",
    "        # Convertimos todo a minusculas\n",
    "        document = document.lower()\n",
    "        \n",
    "        # Realizamos Lematizacion\n",
    "        document = document.split()\n",
    "\n",
    "        document = [stemmer.lemmatize(word) for word in document]\n",
    "        document = ' '.join(document)\n",
    "        \n",
    "        documents.append(document)\n",
    "    \n",
    "    return (documents,base)\n",
    "\n",
    "def identificacion_OCM(well):\n",
    "    '''\n",
    "    Funci贸n que usa un modelo de NPL para identificar las actividades y encontrar el inicio de OCM\n",
    "    ----------------------------------------------------------------------------------------------\n",
    "\n",
    "    - well = Cadena de caracteres con el nombre del pozo a probar\n",
    "\n",
    "    Retorna\n",
    "    - \n",
    "    '''\n",
    "    #-----------------------------------------------------------------------------\n",
    "    # LECTURA Y PREPARACION DE DATOS\n",
    "    #-----------------------------------------------------------------------------\n",
    "\n",
    "    # Lectura de Datos\n",
    "    path='Data.xlsx'\n",
    "    base = pd.read_excel(path)\n",
    "    data = base\n",
    "\n",
    "    # Eliminacion de columnas innecesarias y cambio de nombre de columnas\n",
    "    data = data.rename({'Operaci贸n':\"Operacion\"}, axis=1)\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    # CARGA DE MODELOS\n",
    "    #-----------------------------------------------------------------------------\n",
    "\n",
    "    # Cargue del modelo entrenado\n",
    "    model_rf = pickle.load(open(\"rf.sav\", 'rb'))\n",
    "\n",
    "    # Cargue del vectorizador entrenado\n",
    "    vectorizer = pickle.load(open(\"vectorizer.sav\", 'rb'))\n",
    "\n",
    "    # Cargue del codificador de etiquetas\n",
    "    le = pickle.load(open(\"label_encoder.sav\", 'rb'))\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    # PREPROCESAMIENTO DE LA INFORMACION PARA LA PREDICCION DEL POZO SOLICITADO\n",
    "    #-----------------------------------------------------------------------------\n",
    "\n",
    "    # Preparamos los datos para la prediccion sobre un pozo especifico\n",
    "    X_val,base_val = pre_pro_well(base,well)\n",
    "\n",
    "    # Usamos el vectorizador para transformar los datos para la prediccion\n",
    "    X_val = vectorizer.transform(X_val)\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    # PREDICCION SOBRE DATOS PREPROCESADOS\n",
    "    #-----------------------------------------------------------------------------\n",
    "\n",
    "    # Prediccion\n",
    "    y_val = model_rf.predict(X_val)\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    # VISUALIZACION DE LA PREDICCION\n",
    "    #-----------------------------------------------------------------------------\n",
    "\n",
    "    # Union con datos del pozo\n",
    "    base_val[\"Target\"] = le.inverse_transform(y_val)\n",
    "\n",
    "    # Organizacion del dataframe\n",
    "    base_val = base_val[['Siglas', 'Target', 'Nombre', 'Desde', 'Hasta',\"MD From (ft)\",\"MD to (ft)\",\"Codigo\",\"Subcodigo\",\"Operaci贸n\"]]\n",
    "    \n",
    "    #-----------------------------------------------------------------------------\n",
    "    # BUSQUEDA DE INICIO DE OCM\n",
    "    #-----------------------------------------------------------------------------\n",
    "\n",
    "    # Organizacion de la base en orden descendente\n",
    "    base_val = base_val.sort_values(by=['Desde'],ascending=False)\n",
    "    base_val = base_val.reset_index(drop=True)\n",
    "\n",
    "    # Algoritmo para deteccion de inicio de OCM\n",
    "    fila = 1\n",
    "    while (base_val.Target[fila] == base_val.Target[fila-1]):\n",
    "        fila=fila+1\n",
    "    else:\n",
    "        ID_OCM=fila\n",
    "\n",
    "    ODR_Finish = base_val.Desde[ID_OCM]\n",
    "\n",
    "    base_val = base_val.sort_values(by=['Desde'],ascending=True)\n",
    "    base_val = base_val.reset_index(drop=True)\n",
    "    \n",
    "    respuesta =str(\"El Final del evento ODR en el Pozo \" + str(well) + \" se da en la fecha: \" + str(ODR_Finish)+\"\\n\")\n",
    "    \n",
    "    return(base_val,respuesta,ODR_Finish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identificacion_OCM(\"MOR BL 04\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Diego\n",
      "[nltk_data]     Ojeda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "C:\\Users\\DIEGOO~1\\AppData\\Local\\Temp/ipykernel_9716/1736920892.py:112: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dash import Dash, Input, Output, callback, dash_table\n",
    "import pandas as pd\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "df,respuesta, ODR_Finish = identificacion_OCM(\"MOR BL 04\")\n",
    "\n",
    "app = Dash(external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.Div(respuesta, style={'backgroundColor': 'red', 'color': 'white', 'width': '20%'}),\n",
    "    dash_table.DataTable(\n",
    "        data=df.to_dict('records'),\n",
    "        style_header={\n",
    "            'backgroundColor': '#df8879',\n",
    "            'fontWeight': 'bold'\n",
    "        },\n",
    "        columns=[{'id': c, 'name': c} for c in df.columns],\n",
    "        style_data={\n",
    "            'whiteSpace': 'normal',\n",
    "            'height': 'auto',\n",
    "            'lineHeight': '15px'\n",
    "        },\n",
    "        fixed_rows={'headers': True},\n",
    "        style_cell={'textAlign': 'left','minWidth': 5, 'maxWidth': 300, 'width': 50}, # left align text in columns for readability\n",
    "        style_cell_conditional=[\n",
    "            {'if': {'column_id': 'Siglas'},'width': '3%','textAlign': 'center'},\n",
    "            {'if': {'column_id': 'Target'},'width': '3%','textAlign': 'center'},\n",
    "            {'if': {'column_id': 'Nombre'},'width': '5%','textAlign': 'center'},\n",
    "            {'if': {'column_id': 'Desde'},'width': '10%','textAlign': 'center'},\n",
    "            {'if': {'column_id': 'Hasta'},'width': '10%','textAlign': 'center'},\n",
    "            {'if': {'column_id': 'MD From (ft)'},'width': '6%','textAlign': 'center'},\n",
    "            {'if': {'column_id': 'MD to (ft)'},'width': '6%','textAlign': 'center'},\n",
    "            {'if': {'column_id': 'Codigo'},'width': '6%','textAlign': 'center'},\n",
    "            {'if': {'column_id': 'Subcodigo'},'width': '6%','textAlign': 'center'},\n",
    "            {'if': {'row_index': 'odd'},'backgroundColor': 'rgb(220, 220, 220)',}\n",
    "        ],\n",
    "    #page_size=30,  # we have less data in this example, so setting to 20\n",
    "    style_table={'height': '800px', 'overflowY': 'auto'},\n",
    "    \n",
    "    style_data_conditional=[\n",
    "        {\n",
    "            'if': {\n",
    "                'filter_query': '{Target} = ODR_Finish'\n",
    "            },\n",
    "            'backgroundColor': '#0074D9',\n",
    "            'color': 'white'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    )\n",
    "])\n",
    "@callback(Output('tbl_out', 'children'), Input('tbl', 'active_cell'))\n",
    "    \n",
    "def update_graphs(active_cell):\n",
    "    return str(active_cell) if active_cell else \"Click the table\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "463faa1558641b96f496a1e838e3646ce3a33b56e1a786b33acec479f32e12fc"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
