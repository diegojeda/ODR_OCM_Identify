{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICCION DE FASE USANDO NPL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Importe De Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Diego\n",
      "[nltk_data]     Ojeda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\DIEGOO~1\\AppData\\Local\\Temp/ipykernel_14212/2342114825.py:36: UserWarning: \n",
      "The dash_html_components package is deprecated. Please replace\n",
      "`import dash_html_components as html` with `from dash import html`\n",
      "  import dash_html_components as html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from pylab import *\n",
    "import seaborn as sns\n",
    "from IPython.core.interactiveshell import InteractiveShell  \n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from IPython.display import display, HTML\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from statistics import mean\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import preprocessing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import pickle\n",
    "import nltk\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "from dash import Dash, dash_table\n",
    "import dash_html_components as html\n",
    "from dash import Dash, Input, Output, callback, dash_table\n",
    "import pandas as pd\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MOR BL 04', 'MOR BL 05', 'MOR BL 07', 'MOR BL 08', 'MOR AL 04',\n",
       "       'MOR AL 05', 'MOR AL 01', 'MOR AL 07', 'MOR AL 03',\n",
       "       'MORICHE AO-09', 'MORICHE N-08', 'MORICHE N 03', 'MORICHE N-11',\n",
       "       'MORICHE N 02', 'MORICHE NORTE 08', 'MORICHE NORTE 19',\n",
       "       'MORICHE NORTE 17', 'MORICHE O 11', 'MORICHE O 10', 'MORICHE O 04',\n",
       "       'MORICHE O 08', 'MORICHE O 05', 'MORICHE O 09', 'MORICHE AN2 01',\n",
       "       'MORICHE AN2-03', 'MOR AO 06', 'MOR AO 10', 'MORICHE CC 02',\n",
       "       'MORICHE CC 01', 'MORICHE CC 04', 'MORICHE CC 09', 'MORICHE CC 03',\n",
       "       'MORICHE CC 05', 'MORICHE CC 10', 'MOR U 02 ', 'MOR U 05',\n",
       "       'MOR U 07', 'MOR B 03', 'MOR B 05', 'MOR B 01', 'MOR AI 08',\n",
       "       'MOR AV 05', 'MOR A DESVIADO 2', 'MOR AI 04', 'MOR AI 07',\n",
       "       'MOR AU 18', 'MOR AU 12', 'MOR AU 02 ', 'MOR AU 17', 'MOR AU 16',\n",
       "       'MORICHE BA 10', 'MORICHE BA 15', 'MORICHE BA 02', 'MORICHE BA 13',\n",
       "       'MORICHE BD 06', 'MORICHE BD 02', 'MOR BR 02', 'MOR BR 04 ',\n",
       "       'MOR BR 08 ', 'MOR AY 09', 'MOR AY 15', 'MOR AY 06 ', 'MOR AY 12',\n",
       "       'MOR AY 05', 'MOR AY 04', 'MOR AY 10', 'MOR AY 14', 'MOR AY 03',\n",
       "       'MOR Y 07', 'MOR Y 06', 'MOR AB 03', 'MOR AB 04', 'MORICHE SUR 03',\n",
       "       'MOR CF 06', 'MOR CF 11', 'MOR CF 15', 'MOR CF 14', 'MOR CF 07',\n",
       "       'MORICHE P 03', 'MOR BI 10', 'MOR BI 09', 'MOR BI 07', 'MOR AZ 04',\n",
       "       'MORICHE CB 08', 'MORICHE CB 06', 'MORICHE CB 03', 'MORICHE CB 01',\n",
       "       'MORICHE CB 07', 'MOR AA 02', 'MOR WW AA 01', 'MOR AA 08',\n",
       "       'MOR BG 06', 'MOR BG 08', 'MOR BG 02', 'MOR CD 11', 'MOR CD 07',\n",
       "       'MOR CD 12', 'MORICHE C 03', 'MORICHE C 05', 'MORICHE C 10',\n",
       "       'MOR AC 04', 'MOR AC 02 ', 'MOR AN 13', 'MOR AN 08', 'MOR AN 09',\n",
       "       'MOR AN 12', 'MOR AN 10', 'MOR AN 14', 'MOR AN 15', 'MOR AN 11',\n",
       "       'MOR H 02 ', 'MOR H 10', 'MOR H 09', 'MOR BB 18', 'MORICHE W 10',\n",
       "       'MORICHE W 12', 'MORICHE W 11', 'MORICHE W 04', 'MORICHE W 03',\n",
       "       'MORICHE W 07', 'MORICHE W 05', 'MOR AX 15', 'MOR AX 12',\n",
       "       'MOR AX 14', 'MOR AX 13', 'MORICHE L 01', 'MORICHE L 04',\n",
       "       'MORICHE L-09', 'MORICHE L 02', 'MORICHE L 05', 'MOR L 10',\n",
       "       'MOR L 13', 'MOR BC 09', 'MOR BC 16', 'MOR BC 14', 'MOR BC 07',\n",
       "       'MOR BC 17', 'MOR BC 18', 'MOR BC 10', 'MOR BC 15', 'MOR BC 03',\n",
       "       'MOR J 07', 'MORICHE Q 06', 'MORICHE Q 05', 'MORICHE Q 04',\n",
       "       'MOR AW 06 ', 'MOR AW 10', 'MOR AW 02 ', 'MOR AW 01 ', 'MOR AW 09',\n",
       "       'MOR E 04 ', 'MOR E 09', 'MOR E 12', 'MOR E 07', 'MOR I 05',\n",
       "       'MOR I 01', 'MOR I-10', 'MOR I 04', 'MOR I 09', 'MOR G 12',\n",
       "       'MOR G 13', 'MOR G 05 ', 'MOR G 04 ', 'MORICHE CG 01',\n",
       "       'MORICHE CG 07', 'MORICHE CG 02', 'MORICHE BM 04', 'MORICHE BM 02',\n",
       "       'MORICHE BM 06', 'MORICHE S 03', 'MORICHE S 14', 'MORICHE S 10',\n",
       "       'MOR K 07', 'MOR K 03', 'MOR K 05', 'MOR K 13', 'MOR BE 01',\n",
       "       'MOR BK 07 ', 'MOR BK 02 ', 'MOR BK 06', 'MOR M 03', 'MOR M 08',\n",
       "       'MOR CE 18', 'MOR CE 03', 'MOR CE 15', 'MOR CE 19', 'MOR CE 06',\n",
       "       'MOR CE 14', 'MOR CE 13', 'MOR CE 02', 'MOR BF 08', 'MOR BF 10',\n",
       "       'MOR BF 05', 'MOR BF 09', 'MOR BH 09', 'MOR BH 10',\n",
       "       'MORICHE BP 04', 'MORICHE BP 02', 'MORICHE BP 06', 'MOR AT 03',\n",
       "       'MOR R 05', 'MOR R 03', 'MOR R 04', 'MOR R 09', 'MOR AH2 01',\n",
       "       'MOR AH2 02', 'MORICHE BO 03', 'MORICHE BO 02', 'MORICHE BO 07',\n",
       "       'MOR V 07', 'MOR V 02 ', 'MOR T 05 ', 'MOR T 03 ', 'MORICHE CJ-05',\n",
       "       'MORICHE CJ 04', 'MORICHE CJ 02', 'MOR D 03', 'MOR D 04',\n",
       "       'MOR D 02'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path='Data.xlsx'\n",
    "base = pd.read_excel(path)\n",
    "base.Nombre.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_pro_well(base,well):\n",
    "    '''\n",
    "    FUNCION QUE SELECCIONA UN POZO, TRANSFORMA LOS DATOS COMO INPUT DEL MODELO\n",
    "\n",
    "    - base: Dataframe con los datos de todos los pozos.\n",
    "    - well: cadena de caracteres con el nombre del pozo a evaluar    \n",
    "    '''\n",
    "\n",
    "    # Seleccion del pozo a preprocesar\n",
    "    base = base[base[\"Nombre\"]==well]\n",
    "    \n",
    "    #return base\n",
    "\n",
    "    # Seleccion de la columna de tesxto\n",
    "    X = base[\"Operación\"]\n",
    "    X = X.reset_index(drop=True)\n",
    "\n",
    "    # Libreria de stopwords en ingles\n",
    "    nltk.download('wordnet')\n",
    "\n",
    "    # Lista de textos vacia\n",
    "    documents = []\n",
    "    \n",
    "    # Instanciacion del lematizador en ingles\n",
    "    stemmer = WordNetLemmatizer()\n",
    "    \n",
    "    #return X\n",
    "\n",
    "    # Ciclo for para que recorra todos las filas con las actividaes (textos)\n",
    "    for sen in range(0, len(X)):\n",
    "\n",
    "        # Removemos los caracteres especiales\n",
    "        document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "        \n",
    "        # Removemos todos las cadenas de caracteres de un solo caracter\n",
    "        document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "        \n",
    "        # Removemos caracteres sencillso al inicio\n",
    "        document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "        \n",
    "        # Substituimos dobles espacios por espacios sencillos\n",
    "        document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "        # Removemos caracteres numericos\n",
    "        document = re.sub(r'\\[[0-9]*\\]',' ',document)\n",
    "        \n",
    "        # Convertimos todo a minusculas\n",
    "        document = document.lower()\n",
    "        \n",
    "        # Realizamos Lematizacion\n",
    "        document = document.split()\n",
    "\n",
    "        document = [stemmer.lemmatize(word) for word in document]\n",
    "        document = ' '.join(document)\n",
    "        \n",
    "        documents.append(document)\n",
    "    \n",
    "    return (documents,base)\n",
    "\n",
    "def identificacion_OCM(well):\n",
    "    '''\n",
    "    Función que usa un modelo de NPL para identificar las actividades y encontrar el inicio de OCM\n",
    "    ----------------------------------------------------------------------------------------------\n",
    "\n",
    "    - well = Cadena de caracteres con el nombre del pozo a probar\n",
    "\n",
    "    Retorna\n",
    "    - \n",
    "    '''\n",
    "    #-----------------------------------------------------------------------------\n",
    "    # LECTURA Y PREPARACION DE DATOS\n",
    "    #-----------------------------------------------------------------------------\n",
    "\n",
    "    # Lectura de Datos\n",
    "    path='Data.xlsx'\n",
    "    base = pd.read_excel(path)\n",
    "    base = base.dropna()\n",
    "    base = base.reset_index(drop=True)\n",
    "\n",
    "    data = base\n",
    "\n",
    "    # Eliminacion de columnas innecesarias y cambio de nombre de columnas\n",
    "    data = data.rename({'Operación':\"Operacion\"}, axis=1)\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    # CARGA DE MODELOS\n",
    "    #-----------------------------------------------------------------------------\n",
    "\n",
    "    # Cargue del modelo entrenado\n",
    "    model_rf = pickle.load(open(\"rf.sav\", 'rb'))\n",
    "\n",
    "    # Cargue del vectorizador entrenado\n",
    "    vectorizer = pickle.load(open(\"vectorizer.sav\", 'rb'))\n",
    "\n",
    "    # Cargue del codificador de etiquetas\n",
    "    le = pickle.load(open(\"label_encoder.sav\", 'rb'))\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    # PREPROCESAMIENTO DE LA INFORMACION PARA LA PREDICCION DEL POZO SOLICITADO\n",
    "    #-----------------------------------------------------------------------------\n",
    "\n",
    "    # Preparamos los datos para la prediccion sobre un pozo especifico\n",
    "    X_val,base_val = pre_pro_well(base,well)\n",
    "    #return pre_pro_well(base,well)\n",
    "\n",
    "    # Usamos el vectorizador para transformar los datos para la prediccion\n",
    "    X_val = vectorizer.transform(X_val)\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    # PREDICCION SOBRE DATOS PREPROCESADOS\n",
    "    #-----------------------------------------------------------------------------\n",
    "\n",
    "    # Prediccion\n",
    "    y_val = model_rf.predict(X_val)\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    # VISUALIZACION DE LA PREDICCION\n",
    "    #-----------------------------------------------------------------------------\n",
    "\n",
    "    # Union con datos del pozo\n",
    "    base_val[\"Target\"] = le.inverse_transform(y_val)\n",
    "\n",
    "    # Organizacion del dataframe\n",
    "    base_val = base_val[['Siglas', 'Target', 'Nombre', 'Desde', 'Hasta',\"MD From (ft)\",\"MD to (ft)\",\"Codigo\",\"Subcodigo\",\"Operación\"]]\n",
    "    \n",
    "    #-----------------------------------------------------------------------------\n",
    "    # BUSQUEDA DE INICIO DE OCM\n",
    "    #-----------------------------------------------------------------------------\n",
    "\n",
    "    # Organizacion de la base en orden descendente\n",
    "    base_val = base_val.sort_values(by=['Desde'],ascending=False)\n",
    "    base_val = base_val.reset_index(drop=True)\n",
    "\n",
    "    # Algoritmo para deteccion de inicio de OCM\n",
    "    fila = 1\n",
    "    while (base_val.Target[fila] == base_val.Target[fila-1]):\n",
    "        fila=fila+1\n",
    "    else:\n",
    "        ID_OCM=fila\n",
    "\n",
    "    ODR_Finish = base_val.Hasta[ID_OCM]\n",
    "\n",
    "    base_val = base_val.sort_values(by=['Desde'],ascending=True)\n",
    "    base_val = base_val.reset_index(drop=True)\n",
    "\n",
    "    ODR_Finish = ODR_Finish.strftime(\"%m/%d/%Y %H:%M\")\n",
    "    \n",
    "    respuesta =str(\"El Final del evento ODR en el Pozo \" + str(well) + \" se da en la fecha: \" + str(ODR_Finish)+\"\\n\")\n",
    "    \n",
    "    return(base_val,respuesta,ODR_Finish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Diego\n",
      "[nltk_data]     Ojeda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "C:\\Users\\DIEGOO~1\\AppData\\Local\\Temp/ipykernel_14212/1590325515.py:121: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_val[\"Target\"] = le.inverse_transform(y_val)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'08/07/2011 22:00'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df,respuesta, ODR_Finish = identificacion_OCM(\"MOR BL 07\")\n",
    "ODR_Finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Diego\n",
      "[nltk_data]     Ojeda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "C:\\Users\\DIEGOO~1\\AppData\\Local\\Temp/ipykernel_14212/1590325515.py:121: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_val[\"Target\"] = le.inverse_transform(y_val)\n",
      " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [17/May/2022 17:41:13] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/May/2022 17:41:13] \"GET /_dash-layout HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/May/2022 17:41:13] \"GET /_dash-dependencies HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/May/2022 17:41:13] \"GET /_favicon.ico?v=2.3.1 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/May/2022 17:41:13] \"GET /_dash-component-suites/dash/dash_table/async-highlight.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/May/2022 17:41:13] \"GET /_dash-component-suites/dash/dash_table/async-table.js HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "df,respuesta, ODR_Finish = identificacion_OCM(\"MOR BL 07\")\n",
    "#Rev = identificacion_OCM(\"MOR BL 07\")\n",
    "\n",
    "app = Dash(external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.Div(respuesta, style={'backgroundColor': 'red', 'color': 'white', 'width': '20%'}),\n",
    "    dash_table.DataTable(\n",
    "        data=df.to_dict('records'),\n",
    "        style_header={\n",
    "            'backgroundColor': '#de6e56',\n",
    "            'fontWeight': 'bold'\n",
    "        },\n",
    "        columns=[{'id': c, 'name': c} for c in df.columns],\n",
    "        style_data={\n",
    "            'whiteSpace': 'normal',\n",
    "            'height': 'auto',\n",
    "            'lineHeight': '15px'\n",
    "        },\n",
    "        fixed_rows={'headers': True},\n",
    "        style_cell={'textAlign': 'left','minWidth': 5, 'maxWidth': 300, 'width': 50}, # left align text in columns for readability\n",
    "        style_cell_conditional=[\n",
    "            {'if': {'column_id': 'Siglas'},'width': '3%','textAlign': 'center'},\n",
    "            {'if': {'column_id': 'Target'},'width': '3%','textAlign': 'center'},\n",
    "            {'if': {'column_id': 'Nombre'},'width': '5%','textAlign': 'center'},\n",
    "            {'if': {'column_id': 'Desde'},'width': '10%','textAlign': 'center'},\n",
    "            {'if': {'column_id': 'Hasta'},'width': '10%','textAlign': 'center'},\n",
    "            {'if': {'column_id': 'MD From (ft)'},'width': '6%','textAlign': 'center'},\n",
    "            {'if': {'column_id': 'MD to (ft)'},'width': '6%','textAlign': 'center'},\n",
    "            {'if': {'column_id': 'Codigo'},'width': '6%','textAlign': 'center'},\n",
    "            {'if': {'column_id': 'Subcodigo'},'width': '6%','textAlign': 'center'},\n",
    "            {'if': {'row_index': 'odd'},'backgroundColor': 'rgb(220, 220, 220)',}\n",
    "        ],\n",
    "    #page_size=30,  # we have less data in this example, so setting to 20\n",
    "    style_table={'height': '1200px', 'overflowY': 'auto'},\n",
    "    \n",
    "    style_data_conditional=[\n",
    "        {\n",
    "            'if': {\n",
    "                'filter_query': '{Target} = \"OCM\"'\n",
    "            },\n",
    "            'backgroundColor': '#df8879',\n",
    "            'color': 'white'\n",
    "        }\n",
    "    ]\n",
    "    )\n",
    "])\n",
    "@callback(Output('tbl_out', 'children'), Input('tbl', 'active_cell'))\n",
    "    \n",
    "def update_graphs(active_cell):\n",
    "    return str(active_cell) if active_cell else \"Click the table\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "463faa1558641b96f496a1e838e3646ce3a33b56e1a786b33acec479f32e12fc"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
